{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7994aef6",
   "metadata": {},
   "source": [
    "# 1.Setting up the environment\n",
    "This involves installing all the required packages and limiting the GPU usage growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b565f501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- --------------------\n",
      "absl-py                       1.4.0\n",
      "alabaster                     0.7.12\n",
      "anaconda-client               1.11.0\n",
      "anaconda-navigator            2.3.2\n",
      "anaconda-project              0.11.1\n",
      "anyio                         3.5.0\n",
      "appdirs                       1.4.4\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "arrow                         1.2.2\n",
      "astroid                       2.11.7\n",
      "astropy                       5.1\n",
      "astunparse                    1.6.3\n",
      "atomicwrites                  1.4.0\n",
      "attrs                         21.4.0\n",
      "Automat                       20.2.0\n",
      "autopep8                      1.6.0\n",
      "Babel                         2.9.1\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "backports.tempfile            1.0\n",
      "backports.weakref             1.0.post1\n",
      "bcrypt                        3.2.0\n",
      "beautifulsoup4                4.11.1\n",
      "binaryornot                   0.4.4\n",
      "bitarray                      2.5.1\n",
      "bkcharts                      0.2\n",
      "black                         22.6.0\n",
      "bleach                        4.1.0\n",
      "bokeh                         2.4.3\n",
      "boto3                         1.24.28\n",
      "botocore                      1.27.28\n",
      "Bottleneck                    1.3.5\n",
      "brotlipy                      0.7.0\n",
      "cachetools                    5.2.1\n",
      "certifi                       2022.9.14\n",
      "cffi                          1.15.1\n",
      "chardet                       4.0.0\n",
      "charset-normalizer            2.0.4\n",
      "click                         8.0.4\n",
      "cloudpickle                   2.0.0\n",
      "clyent                        1.2.2\n",
      "colorama                      0.4.5\n",
      "colorcet                      3.0.0\n",
      "comtypes                      1.1.10\n",
      "conda                         22.11.1\n",
      "conda-build                   3.22.0\n",
      "conda-content-trust           0.1.3\n",
      "conda-pack                    0.6.0\n",
      "conda-package-handling        1.9.0\n",
      "conda-repo-cli                1.0.20\n",
      "conda-token                   0.4.0\n",
      "conda-verify                  3.4.2\n",
      "constantly                    15.1.0\n",
      "cookiecutter                  1.7.3\n",
      "cryptography                  37.0.1\n",
      "cssselect                     1.1.0\n",
      "cycler                        0.11.0\n",
      "Cython                        0.29.32\n",
      "cytoolz                       0.11.0\n",
      "daal4py                       2021.6.0\n",
      "dask                          2022.7.0\n",
      "datashader                    0.14.1\n",
      "datashape                     0.5.4\n",
      "debugpy                       1.5.1\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "diff-match-patch              20200713\n",
      "dill                          0.3.4\n",
      "distributed                   2022.7.0\n",
      "docutils                      0.18.1\n",
      "entrypoints                   0.4\n",
      "et-xmlfile                    1.1.0\n",
      "fastjsonschema                2.16.2\n",
      "filelock                      3.6.0\n",
      "flake8                        4.0.1\n",
      "Flask                         1.1.2\n",
      "flatbuffers                   23.1.4\n",
      "fonttools                     4.25.0\n",
      "fsspec                        2022.7.1\n",
      "future                        0.18.2\n",
      "gast                          0.4.0\n",
      "gensim                        4.1.2\n",
      "glob2                         0.7\n",
      "google-auth                   2.16.0\n",
      "google-auth-oauthlib          0.4.6\n",
      "google-pasta                  0.2.0\n",
      "greenlet                      1.1.1\n",
      "grpcio                        1.51.1\n",
      "h5py                          3.7.0\n",
      "HeapDict                      1.0.1\n",
      "holoviews                     1.15.0\n",
      "hvplot                        0.8.0\n",
      "hyperlink                     21.0.0\n",
      "idna                          3.3\n",
      "imagecodecs                   2021.8.26\n",
      "imageio                       2.19.3\n",
      "imagesize                     1.4.1\n",
      "importlib-metadata            4.11.3\n",
      "incremental                   21.3.0\n",
      "inflection                    0.5.1\n",
      "iniconfig                     1.1.1\n",
      "intake                        0.6.5\n",
      "intervaltree                  3.1.0\n",
      "ipykernel                     6.15.2\n",
      "ipython                       7.31.1\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    7.6.5\n",
      "isort                         5.9.3\n",
      "itemadapter                   0.3.0\n",
      "itemloaders                   1.0.4\n",
      "itsdangerous                  2.0.1\n",
      "jdcal                         1.4.1\n",
      "jedi                          0.18.1\n",
      "jellyfish                     0.9.0\n",
      "Jinja2                        2.11.3\n",
      "jinja2-time                   0.2.0\n",
      "jmespath                      0.10.0\n",
      "joblib                        1.1.0\n",
      "json5                         0.9.6\n",
      "jsonschema                    4.16.0\n",
      "jupyter                       1.0.0\n",
      "jupyter_client                7.3.4\n",
      "jupyter-console               6.4.3\n",
      "jupyter_core                  4.11.1\n",
      "jupyter-server                1.18.1\n",
      "jupyterlab                    3.4.4\n",
      "jupyterlab-pygments           0.1.2\n",
      "jupyterlab-server             2.10.3\n",
      "jupyterlab-widgets            1.0.0\n",
      "keras                         2.10.0\n",
      "Keras-Preprocessing           1.1.2\n",
      "keyring                       23.4.0\n",
      "kiwisolver                    1.4.2\n",
      "lazy-object-proxy             1.6.0\n",
      "libarchive-c                  2.9\n",
      "libclang                      15.0.6.1\n",
      "llvmlite                      0.38.0\n",
      "locket                        1.0.0\n",
      "lxml                          4.9.1\n",
      "lz4                           3.1.3\n",
      "Markdown                      3.3.4\n",
      "MarkupSafe                    2.0.1\n",
      "matplotlib                    3.5.2\n",
      "matplotlib-inline             0.1.6\n",
      "mccabe                        0.6.1\n",
      "menuinst                      1.4.19\n",
      "mistune                       0.8.4\n",
      "mkl-fft                       1.3.1\n",
      "mkl-random                    1.2.2\n",
      "mkl-service                   2.4.0\n",
      "mock                          4.0.3\n",
      "mpmath                        1.2.1\n",
      "msgpack                       1.0.3\n",
      "multipledispatch              0.6.0\n",
      "munkres                       1.1.4\n",
      "mypy-extensions               0.4.3\n",
      "navigator-updater             0.3.0\n",
      "nbclassic                     0.3.5\n",
      "nbclient                      0.5.13\n",
      "nbconvert                     6.4.4\n",
      "nbformat                      5.5.0\n",
      "nest-asyncio                  1.5.5\n",
      "networkx                      2.8.4\n",
      "nltk                          3.7\n",
      "nose                          1.3.7\n",
      "notebook                      6.4.12\n",
      "numba                         0.55.1\n",
      "numexpr                       2.8.3\n",
      "numpy                         1.21.5\n",
      "numpydoc                      1.4.0\n",
      "oauthlib                      3.2.2\n",
      "olefile                       0.46\n",
      "openpyxl                      3.0.10\n",
      "opt-einsum                    3.3.0\n",
      "packaging                     21.3\n",
      "pandas                        1.4.4\n",
      "pandocfilters                 1.5.0\n",
      "panel                         0.13.1\n",
      "param                         1.12.0\n",
      "paramiko                      2.8.1\n",
      "parsel                        1.6.0\n",
      "parso                         0.8.3\n",
      "partd                         1.2.0\n",
      "pathlib                       1.0.1\n",
      "pathspec                      0.9.0\n",
      "patsy                         0.5.2\n",
      "pep8                          1.7.1\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.2.0\n",
      "pip                           22.2.2\n",
      "pkginfo                       1.8.2\n",
      "platformdirs                  2.5.2\n",
      "plotly                        5.9.0\n",
      "pluggy                        1.0.0\n",
      "poyo                          0.5.0\n",
      "prometheus-client             0.14.1\n",
      "prompt-toolkit                3.0.20\n",
      "Protego                       0.1.16\n",
      "protobuf                      3.19.6\n",
      "psutil                        5.9.0\n",
      "ptyprocess                    0.7.0\n",
      "py                            1.11.0\n",
      "pyasn1                        0.4.8\n",
      "pyasn1-modules                0.2.8\n",
      "pycodestyle                   2.8.0\n",
      "pycosat                       0.6.3\n",
      "pycparser                     2.21\n",
      "pyct                          0.4.8\n",
      "pycurl                        7.45.1\n",
      "PyDispatcher                  2.0.5\n",
      "pydocstyle                    6.1.1\n",
      "pyerfa                        2.0.0\n",
      "pyflakes                      2.4.0\n",
      "Pygments                      2.11.2\n",
      "PyHamcrest                    2.0.2\n",
      "PyJWT                         2.4.0\n",
      "pylint                        2.14.5\n",
      "pyls-spyder                   0.4.0\n",
      "PyNaCl                        1.5.0\n",
      "pyntcloud                     0.3.1\n",
      "pyodbc                        4.0.34\n",
      "pyOpenSSL                     22.0.0\n",
      "pyparsing                     3.0.9\n",
      "pyrsistent                    0.18.0\n",
      "PySocks                       1.7.1\n",
      "pytest                        7.1.2\n",
      "python-dateutil               2.8.2\n",
      "python-lsp-black              1.0.0\n",
      "python-lsp-jsonrpc            1.0.0\n",
      "python-lsp-server             1.3.3\n",
      "python-slugify                5.0.2\n",
      "python-snappy                 0.6.0\n",
      "pytz                          2022.1\n",
      "pyviz-comms                   2.0.2\n",
      "PyWavelets                    1.3.0\n",
      "pywin32                       302\n",
      "pywin32-ctypes                0.2.0\n",
      "pywinpty                      2.0.2\n",
      "PyYAML                        6.0\n",
      "pyzmq                         23.2.0\n",
      "QDarkStyle                    3.0.2\n",
      "qstylizer                     0.1.10\n",
      "QtAwesome                     1.0.3\n",
      "qtconsole                     5.2.2\n",
      "QtPy                          2.2.0\n",
      "queuelib                      1.5.0\n",
      "regex                         2022.7.9\n",
      "requests                      2.28.1\n",
      "requests-file                 1.5.1\n",
      "requests-oauthlib             1.3.1\n",
      "rope                          0.22.0\n",
      "rsa                           4.9\n",
      "Rtree                         0.9.7\n",
      "ruamel.yaml                   0.17.21\n",
      "ruamel.yaml.clib              0.2.6\n",
      "ruamel-yaml-conda             0.15.100\n",
      "s3transfer                    0.6.0\n",
      "scikit-image                  0.19.2\n",
      "scikit-learn                  1.0.2\n",
      "scikit-learn-intelex          2021.20221004.171935\n",
      "scipy                         1.9.1\n",
      "Scrapy                        2.6.2\n",
      "seaborn                       0.11.2\n",
      "Send2Trash                    1.8.0\n",
      "service-identity              18.1.0\n",
      "setuptools                    63.4.1\n",
      "sip                           4.19.13\n",
      "six                           1.16.0\n",
      "smart-open                    5.2.1\n",
      "sniffio                       1.2.0\n",
      "snowballstemmer               2.2.0\n",
      "sortedcollections             2.1.0\n",
      "sortedcontainers              2.4.0\n",
      "soupsieve                     2.3.1\n",
      "Sphinx                        5.0.2\n",
      "sphinxcontrib-applehelp       1.0.2\n",
      "sphinxcontrib-devhelp         1.0.2\n",
      "sphinxcontrib-htmlhelp        2.0.0\n",
      "sphinxcontrib-jsmath          1.0.1\n",
      "sphinxcontrib-qthelp          1.0.3\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "spyder                        5.2.2\n",
      "spyder-kernels                2.2.1\n",
      "SQLAlchemy                    1.4.39\n",
      "statsmodels                   0.13.2\n",
      "sympy                         1.10.1\n",
      "tables                        3.6.1\n",
      "tabulate                      0.8.10\n",
      "TBB                           0.2\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.0.1\n",
      "tensorboard                   2.10.1\n",
      "tensorboard-data-server       0.6.1\n",
      "tensorboard-plugin-wit        1.8.1\n",
      "tensorflow                    2.10.1\n",
      "tensorflow-estimator          2.10.0\n",
      "tensorflow-gpu                2.10.1\n",
      "tensorflow-io-gcs-filesystem  0.29.0\n",
      "termcolor                     2.2.0\n",
      "terminado                     0.13.1\n",
      "testpath                      0.6.0\n",
      "text-unidecode                1.3\n",
      "textdistance                  4.2.1\n",
      "threadpoolctl                 2.2.0\n",
      "three-merge                   0.1.1\n",
      "tifffile                      2021.7.2\n",
      "tinycss                       0.4\n",
      "tldextract                    3.2.0\n",
      "toml                          0.10.2\n",
      "tomli                         2.0.1\n",
      "tomlkit                       0.11.1\n",
      "toolz                         0.11.2\n",
      "tornado                       6.1\n",
      "tqdm                          4.64.1\n",
      "traitlets                     5.1.1\n",
      "Twisted                       22.2.0\n",
      "twisted-iocpsupport           1.0.2\n",
      "typing_extensions             4.3.0\n",
      "ujson                         5.4.0\n",
      "Unidecode                     1.2.0\n",
      "urllib3                       1.26.11\n",
      "w3lib                         1.21.0\n",
      "watchdog                      2.1.6\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "websocket-client              0.58.0\n",
      "Werkzeug                      2.0.3\n",
      "wheel                         0.37.1\n",
      "widgetsnbextension            3.5.2\n",
      "win-inet-pton                 1.1.0\n",
      "win-unicode-console           0.5\n",
      "wincertstore                  0.2\n",
      "wrapt                         1.14.1\n",
      "xarray                        0.20.1\n",
      "xlrd                          2.0.1\n",
      "XlsxWriter                    3.0.3\n",
      "xlwings                       0.27.15\n",
      "yapf                          0.31.0\n",
      "zict                          2.1.0\n",
      "zipp                          3.8.0\n",
      "zope.interface                5.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f68bff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4233196721562717544\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2258055988\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9939576048862961524\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b108ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing tensorflow package\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "528d2a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing other packages\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LeakyReLU,Dropout,Input,ReLU,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryCrossentropy as bce, RootMeanSquaredError as rmse\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b04c06",
   "metadata": {},
   "source": [
    "# 2. Importing the dataset\n",
    "\n",
    "The dataset contains the positions of centres of the 10 magnetostrictive spheres of radius 0.4 cm dispersed throughout the piezoelectric matrix and the corresponding ME coupling coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab09cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"ME Composite Dataset Actual 2.csv\")\n",
    "train_data_filter = train_data[:][train_data[\"Reject\"] == False]\n",
    "train_data_filter = train_data_filter.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c978c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c52f074",
   "metadata": {},
   "source": [
    "# 3.Building ANN for evaluation of design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97fcb60",
   "metadata": {},
   "source": [
    "### 3.1. ANN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c1deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN():\n",
    "    \n",
    "    input_layer = Input(shape=(30,))\n",
    "    \n",
    "    dense1 = Dense(35)(input_layer)\n",
    "    batchnorm1 = BatchNormalization()(dense1)\n",
    "    leakyRelu1 = LeakyReLU(0.2)(batchnorm1)\n",
    "    dropout1 = Dropout(0.1)(leakyRelu1)\n",
    "    \n",
    "    dense2 = Dense(40)(dropout1)\n",
    "    batchnorm2 = BatchNormalization()(dense2)\n",
    "    leakyRelu2 = LeakyReLU(0.2)(batchnorm2)\n",
    "    dropout2 = Dropout(0.1)(leakyRelu2)\n",
    "    \n",
    "    \n",
    "    dense3 = Dense(35)(dropout2)\n",
    "    batchnorm3 = BatchNormalization()(dense3)\n",
    "    leakyRelu3 = LeakyReLU(0.2)(batchnorm3)\n",
    "    dropout3 = Dropout(0.1)(leakyRelu3)\n",
    "    \n",
    "    output_layer = Dense(1)(dropout3)\n",
    "    \n",
    "    model = Model(inputs=input_layer,outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea1a21",
   "metadata": {},
   "source": [
    "### 3.2. Creating instance of ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d64473",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = ANN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2dbca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb5c97",
   "metadata": {},
   "source": [
    "### 3.3. Loading weights onto ANN(shouldn't be done for step after last design round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c43e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.load_weights('ann.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616a00af",
   "metadata": {},
   "source": [
    "### 3.4. Defining optimizers and losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212a631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_opt = Adam(learning_rate = 0.01)\n",
    "ann_loss = MeanSquaredError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5ada0",
   "metadata": {},
   "source": [
    "### 3.5.Compiling the ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e180b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(ann_opt,ann_loss,metrics=['RootMeanSquaredError'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cab759",
   "metadata": {},
   "source": [
    "# 4. Building GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16303b2",
   "metadata": {},
   "source": [
    "### 4.1. Building the Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e1fda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    \n",
    "    input_layer = Input(shape=(2,))\n",
    "    \n",
    "    dense1 = Dense(4)(input_layer)\n",
    "    batchnorm1 = BatchNormalization()(dense1)\n",
    "    leakyRelu1 = LeakyReLU(0.1)(batchnorm1)\n",
    "    \n",
    "    dense2 = Dense(8)(leakyRelu1)\n",
    "    batchnorm2 = BatchNormalization()(dense2)\n",
    "    leakyRelu2 = LeakyReLU(0.1)(batchnorm2)\n",
    "    \n",
    "    dense3 = Dense(16)(leakyRelu2)\n",
    "    batchnorm3 = BatchNormalization()(dense3)\n",
    "    leakyRelu3 = LeakyReLU(0.1)(batchnorm3)\n",
    "    \n",
    "    output_layer = Dense(30)(leakyRelu3)\n",
    "\n",
    "    model = Model(inputs=input_layer,outputs=output_layer)\n",
    "\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de816b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef44ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 12        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 4)                16        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 40        \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                144       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 30)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 818\n",
      "Trainable params: 762\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f026f2",
   "metadata": {},
   "source": [
    "### 4.2 Building the Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8af7c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "  \n",
    "    input_layer = Input(shape=(30,))\n",
    "    \n",
    "    # Real or fake classification\n",
    "    dense1 = Dense(16)(input_layer)\n",
    "    batchnorm1 = BatchNormalization()(dense1)\n",
    "    leakyRelu1 = LeakyReLU(0.1)(batchnorm1)\n",
    "    \n",
    "    dense2 = Dense(8)(leakyRelu1)\n",
    "    batchnorm2 = BatchNormalization()(dense2)\n",
    "    leakyRelu2 = LeakyReLU(0.1)(batchnorm2)    \n",
    "    \n",
    "    dense3 = Dense(4)(leakyRelu2)\n",
    "    batchnorm3 = BatchNormalization()(dense3)\n",
    "    leakyRelu3 = LeakyReLU(0.1)(batchnorm3)\n",
    "    \n",
    "    dense4 = Dense(2)(leakyRelu3)\n",
    "    batchnorm4 = BatchNormalization()(dense4)\n",
    "    leakyRelu4 = LeakyReLU(0.1)(batchnorm4)\n",
    "    \n",
    "    # Pass to Output layer\n",
    "    output_layer = Dense(1, activation='sigmoid')(leakyRelu4)\n",
    "\n",
    "    model = Model(inputs = input_layer, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5fe10a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca85b4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 30)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                496       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 4)                16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 2)                8         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 801\n",
      "Trainable params: 741\n",
      "Non-trainable params: 60\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0d6f7",
   "metadata": {},
   "source": [
    "### 4.3. Loading weights onto generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4537d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_weights('generator.h5')\n",
    "discriminator.load_weights('discriminator.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7757cc",
   "metadata": {},
   "source": [
    "### 4.4. Defining optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9077f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_opt = Adam(learning_rate=0.001)\n",
    "d_opt = Adam(learning_rate=0.0001)\n",
    "g_loss = BinaryCrossentropy()\n",
    "d_loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f99e47",
   "metadata": {},
   "source": [
    "### 4.5. Building sub-classed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83d3be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeGAN(Model):\n",
    "\n",
    "    def __init__(self,generator,discriminator, *args, **kwargs):\n",
    "        \n",
    "         # Pass through args and kwargs to base class \n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Creating attributes for generator and discriminator\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "  \n",
    "    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs):\n",
    "        # Compile with base class\n",
    "        super().compile(*args, **kwargs)\n",
    "        # Creating attributes for losses and optimizers\n",
    "        self.g_opt = g_opt\n",
    "        self.d_opt = d_opt\n",
    "        self.g_loss = g_loss\n",
    "        self.d_loss = d_loss\n",
    "  \n",
    "    def train_step(self, batch):\n",
    "        # Getting the data\n",
    "        real_data = batch\n",
    "        fake_data = self.generator(tf.random.normal(shape=[120,2]),training=False)\n",
    "        fake_data /= tf.norm(fake_data,axis=1)[:,None]\n",
    "        fake_data *= 30\n",
    "\n",
    "        # Training the discriminator\n",
    "        with tf.GradientTape()  as d_tape:\n",
    "            # Passing real and fake images to the discriminator model\n",
    "            yhat_real = self.discriminator(real_data, training=True)\n",
    "            yhat_fake = self.discriminator(fake_data, training=True)\n",
    "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
    "\n",
    "            # Creating labels for real and fake images\n",
    "            y_realfake = tf.concat([tf.ones_like(yhat_real), tf.zeros_like(yhat_fake)], axis=0) \n",
    "\n",
    "            # Adding some noise to the TRUE outputs\n",
    "            noise_real = -0.1*tf.random.uniform(tf.shape(yhat_real))\n",
    "            noise_fake = 0.1*tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake += tf.concat([noise_real, noise_fake], axis = 0)\n",
    "\n",
    "            # Calculating the loss\n",
    "            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
    "            \n",
    "        # Applying backpropagation - nn learn \n",
    "        dgrad = d_tape.gradient([total_d_loss], self.discriminator.trainable_variables)\n",
    "        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
    "\n",
    "        # Training the generator\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            # Generating new images\n",
    "            gen_data = self.generator(tf.random.normal(shape=[120,2]), training=True)\n",
    "            gen_data /= tf.norm(gen_data,axis=1)[:,None]\n",
    "            gen_data *= 30\n",
    "            # Creating the predicted labels\n",
    "            yhat_gen = self.discriminator(gen_data, training=False)\n",
    "            # Calculate loss\n",
    "            total_g_loss = self.g_loss(tf.ones_like(yhat_gen), yhat_gen)\n",
    "\n",
    "        # Applying backprop\n",
    "        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
    "\n",
    "        return {\"d_loss\":total_d_loss,\"g_loss\":total_g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d004c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of subclassed model\n",
    "compositegan = CompositeGAN(generator,discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d32a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "compositegan.compile(g_opt, d_opt, g_loss, d_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9646fb20",
   "metadata": {},
   "source": [
    "# 5. Adaptive Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c90523",
   "metadata": {},
   "source": [
    "Mo = 349 <br>\n",
    "No = 50 <br>\n",
    "M = 120 <br>\n",
    "N = 30 <br>\n",
    "p = 8 <br>\n",
    "Me = 360 <br>\n",
    "No mutation <br>\n",
    "Sequence of steps: Design round 0 - 5.2, 5.3, 5.4, 5.6, 5.7, 5.8, 5.9, 5.10, 5.11 <br>\n",
    "Design rounds 1 till last: 5.12,5.3, 5.5, 5.7, 5.8, 5.9, 5.11, 5.12, 5.3 <br>\n",
    "After last design round: 5.13, 5.14\n",
    "\n",
    "### 5.1. Initializing the adaptive algorithm parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e119207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mo = 349\n",
    "No = 50\n",
    "M = 120\n",
    "N = 30\n",
    "p = 8\n",
    "Me = 360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77d7949",
   "metadata": {},
   "source": [
    "### 5.2. Sampling data for training ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f120bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ANN = train_data_filter.sample(No)\n",
    "train_data_ANN.to_csv(r\"Training data 2\\ME_Composite_Design_ANN_round0.csv\",index=False)\n",
    "X = train_data_ANN.iloc[:,1:-2]\n",
    "y = train_data_ANN.iloc[:,-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2306ebdc",
   "metadata": {},
   "source": [
    "### 5.3. Training ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126cb63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_hist = ann.fit(X,y,epochs=200,batch_size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee8a71a",
   "metadata": {},
   "source": [
    "#### 5.3.1. ANN loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66874454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.suptitle('Regression loss')\n",
    "plt.plot(ann_hist.history['root_mean_squared_error'], label='Regression_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853401c8",
   "metadata": {},
   "source": [
    "### 5.4. Predicting ME coupling coefficient for the total population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8504d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(ann.predict(train_data_filter.iloc[:,1:-2]),columns = ['ME_Coupling_coefficient_pred'])\n",
    "pop_data = pd.concat([train_data_filter.iloc[:,1:-2],y_pred], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9dce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eccf2b",
   "metadata": {},
   "source": [
    "### 5.5 Performing inverse design with GAN-ANN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27df2b",
   "metadata": {},
   "source": [
    "Steps for first generation: 5.5.1, 5.5.2, 5.5.3, 5.5.4/5.5.5 <br>\n",
    "Steps for subsequent generations: 5.5.3, 5.5.4/5.5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889c150e",
   "metadata": {},
   "source": [
    "#### 5.5.1. Generating P samples from GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e511af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_var = np.random.normal(size=(p,2))\n",
    "pop_X = generator.predict(latent_var)\n",
    "latent_var = pd.DataFrame(latent_var,columns=['var1','var2'])\n",
    "pop_X_cols = ['Sphere 1x','Sphere 1y','Sphere 1z','Sphere 2x','Sphere 2y','Sphere 2z','Sphere 3x','Sphere 3y','Sphere 3z','Sphere 4x','Sphere 4y','Sphere 4z','Sphere 5x','Sphere 5y','Sphere 5z','Sphere 6x','Sphere 6y','Sphere 6z','Sphere 7x','Sphere 7y','Sphere 7z','Sphere 8x','Sphere 8y','Sphere 8z','Sphere 9x','Sphere 9y','Sphere 9z','Sphere 10x','Sphere 10y','Sphere 10z']\n",
    "pop_X = pd.DataFrame(pop_X,columns = pop_X_cols)\n",
    "pop_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e37fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(ann.predict(pop_X),columns = ['ME_Coupling_coefficient_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_dataset = pd.concat([latent_var,y_pred],axis=1)\n",
    "ga_dataset = ga_dataset.sort_values(by=['ME_Coupling_coefficient_pred'], ascending = False).reset_index(drop=True)\n",
    "ga_dataset['Mating_no'] = round((ga_dataset['ME_Coupling_coefficient_pred']/ga_dataset['ME_Coupling_coefficient_pred'].sum())*p).astype(int)\n",
    "ga_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa62cb",
   "metadata": {},
   "source": [
    "Creating mating pool for first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844fe8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_dataset['var1'] = round(ga_dataset['var1'],3)\n",
    "ga_dataset['var2'] = round(ga_dataset['var2'],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7042507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ga_dataset['Mating_no'].sum() < p:\n",
    "    s = ga_dataset['Mating_no'].sum()\n",
    "    ga_dataset['Mating_no'][0] += (p-s)\n",
    "j = 1\n",
    "while ga_dataset['Mating_no'].sum() > p:\n",
    "    if ga_dataset['Mating_no'][p-j] == 0:\n",
    "        j += 1\n",
    "    ga_dataset['Mating_no'][p-j] -= 1\n",
    "mate_pool = ga_dataset[ga_dataset['Mating_no']>0][:]\n",
    "mate_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87afdcf5",
   "metadata": {},
   "source": [
    "Calculating average fitness for first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762cab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fitness_hist = []\n",
    "avg_fitness_hist.append(ga_dataset['ME_Coupling_coefficient_pred'].mean())\n",
    "print(\"History of GA:\",avg_fitness_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddb269c",
   "metadata": {},
   "source": [
    "#### 5.5.2. Decimal to binary conversion and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3de403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_to_binary(num):\n",
    "    num = int(num*1000)\n",
    "    binary = []\n",
    "    abs_num = abs(num)\n",
    "    while abs_num > 0:\n",
    "        binary.insert(0,abs_num%2)\n",
    "        abs_num //= 2\n",
    "    if num < 0:\n",
    "        binary.insert(0,1)\n",
    "    else:\n",
    "        binary.insert(0,0)\n",
    "    return binary\n",
    "\n",
    "def binary_to_dec(binary):\n",
    "    length = len(binary)\n",
    "    num = 0\n",
    "    for i in range(1,length):\n",
    "        num += (2**(length-i-1))*binary[i]\n",
    "    num /= 1000\n",
    "    if binary[0] == 1:\n",
    "        num = -num\n",
    "    return num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b491b5",
   "metadata": {},
   "source": [
    "#### 5.5.3. Genetic Algorithm(to be repeated until convergence) - uses uniform crossover and no mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043adb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA(mate_pool):\n",
    "    bin_rep = []\n",
    "    mate_count = np.shape(mate_pool)[0]\n",
    "    for i in range(0,mate_count):\n",
    "        row = []\n",
    "        row.append(dec_to_binary(mate_pool['var1'][i]))\n",
    "        row.append(dec_to_binary(mate_pool['var2'][i]))\n",
    "        for j in range(0,mate_pool['Mating_no'][i]):\n",
    "            bin_rep.append(row)\n",
    "    print(\"Binary_rep before mating\")\n",
    "    for i in range(0,p):\n",
    "        print(bin_rep[i][0],bin_rep[i][1])\n",
    "    mate_list = np.arange(0,p)\n",
    "    random.shuffle(mate_list)\n",
    "    for i in range(0,p,2):\n",
    "        partner = i+1\n",
    "        for j in range(0,2):\n",
    "            len1 = len(bin_rep[mate_list[i]][j])\n",
    "            len2 = len(bin_rep[mate_list[partner]][j])\n",
    "            if len1 > len2:\n",
    "                for k in range(0,len1-len2):\n",
    "                    bin_rep[mate_list[partner]][j].insert(0,0)\n",
    "            elif len1 < len2:\n",
    "                for k in range(0,len2-len1):\n",
    "                    bin_rep[mate_list[i]][j].insert(0,0)\n",
    "            cross_over = [random.choice([0,1]) for k in range(0,max(len1,len2))]\n",
    "            for k in range(0,max(len1,len2)):\n",
    "                if cross_over[k] == 1:\n",
    "                    temp = bin_rep[mate_list[i]][j][k]\n",
    "                    bin_rep[mate_list[i]][j][k] = bin_rep[mate_list[partner]][j][k]\n",
    "                    bin_rep[mate_list[partner]][j][k] = temp\n",
    "    print(\"Binary_rep after mating\")\n",
    "    for i in range(0,p):\n",
    "        print(bin_rep[i][0],bin_rep[i][1])\n",
    "    new_pop = []\n",
    "    for i in range(0,p):\n",
    "        row = []\n",
    "        for j in range(0,2):\n",
    "            row.append(binary_to_dec(bin_rep[i][j]))\n",
    "        new_pop.append(row)\n",
    "    new_pop = np.array(new_pop)\n",
    "    new_pop = pd.DataFrame(new_pop,columns=['var1','var2'])\n",
    "    print(new_pop)\n",
    "    return new_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d48722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pop_latent = GA(mate_pool)\n",
    "new_pop_X = pd.DataFrame(generator.predict(new_pop_latent),columns = pop_X_cols)\n",
    "y_pred = pd.DataFrame(ann.predict(new_pop_X),columns = ['ME_Coupling_coefficient_pred'])\n",
    "new_pop_data = pd.concat([new_pop_latent,y_pred],axis = 1)\n",
    "new_pop_data = new_pop_data.sort_values(by=['ME_Coupling_coefficient_pred'], ascending = False).reset_index(drop=True)\n",
    "new_pop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c59c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fitness_hist.append(new_pop_data['ME_Coupling_coefficient_pred'].mean())\n",
    "print(\"History of GA:\",avg_fitness_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa79cd2c",
   "metadata": {},
   "source": [
    "#### 5.5.4 If ME_coupling coefficient shows signs of convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e5d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pop_data = pd.concat([new_pop_X,y_pred],axis = 1).sort_values(by=['ME_Coupling_coefficient_pred'], ascending = False)\n",
    "new_pop_data.to_csv(r\"Population_data 3\\Pop_data2.csv\", index = False)\n",
    "parent_X = new_pop_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e365980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pop_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c11b420",
   "metadata": {},
   "source": [
    "#### 5.5.5 If ME coupling coefficient does not show signs of convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead0b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_dataset = new_pop_data\n",
    "ga_dataset['Mating_no'] = round((ga_dataset['ME_Coupling_coefficient_pred']/ga_dataset['ME_Coupling_coefficient_pred'].sum())*p).astype(int)\n",
    "ga_dataset['var1'] = round(ga_dataset['var1'],3)\n",
    "ga_dataset['var2'] = round(ga_dataset['var2'],3)\n",
    "if ga_dataset['Mating_no'].sum() < p:\n",
    "    s = ga_dataset['Mating_no'].sum()\n",
    "    ga_dataset['Mating_no'][0] += (p-s)\n",
    "j = 1\n",
    "while ga_dataset['Mating_no'].sum() > p:\n",
    "    if ga_dataset['Mating_no'][p-j] == 0:\n",
    "        j += 1\n",
    "    ga_dataset['Mating_no'][p-j] -= 1\n",
    "mate_pool = ga_dataset[ga_dataset['Mating_no']>0][:]\n",
    "mate_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cf281d",
   "metadata": {},
   "source": [
    "### 5.6. Selecting the top designs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data = pop_data.sort_values(by=['ME_Coupling_coefficient_pred'], ascending = False)\n",
    "parent_data = pop_data.head(M)\n",
    "parent_data = parent_data.reset_index(drop = True)\n",
    "parent_data.to_csv(r\"Parent_data 3\\parent_data0.csv\", index = False)\n",
    "parent_X = parent_data.iloc[:,:-1]\n",
    "parent_y = parent_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe80a6c3",
   "metadata": {},
   "source": [
    "### 5.7. Performing expansion of  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea9fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_X = parent_X\n",
    "for i in range(0,44):\n",
    "    mutated_set = parent_X  + np.random.normal(size = 30)\n",
    "    extend_X = pd.concat([extend_X ,mutated_set])\n",
    "extend_X = extend_X.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf49e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e54bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in extend_X.columns:\n",
    "    extend_X.loc[extend_X[col] > 30, col] = 30\n",
    "    extend_X.loc[extend_X[col] < -30, col] = -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8a48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07af1055",
   "metadata": {},
   "source": [
    "### 5.8. Predicting ME coupling coefficient in expanded population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_extend = pd.DataFrame(ann.predict(extend_X),columns = ['ME_Coupling_coefficient_pred'])\n",
    "extend_pop = pd.concat([extend_X,y_pred_extend],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8114a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ccc34",
   "metadata": {},
   "source": [
    "### 5.9. Selecting top designs from extended population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a061de",
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_pop = extend_pop.sort_values(by=['ME_Coupling_coefficient_pred'], ascending=False)\n",
    "parent_data = extend_pop.head(M).reset_index(drop = True)\n",
    "parent_data.to_csv(r\"Parent_data 3\\parent_data3.csv\", index = False)\n",
    "parent_X = parent_data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cc58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_data = pd.read_csv(r\"Parent_data 2\\parent_data4.csv\")\n",
    "parent_X = parent_data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d52747",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d4472",
   "metadata": {},
   "source": [
    "### 5.10. Training GAN with the parent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e40882",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = compositegan.fit(parent_X,epochs=2000, batch_size = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110be1e3",
   "metadata": {},
   "source": [
    "#### 5.10.1. Performance Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cff008",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Generator - Discriminator Loss')\n",
    "plt.plot(train_hist.history['d_loss'], label='Discriminator_loss')\n",
    "plt.plot(train_hist.history['g_loss'], label='Generator_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0b00a1",
   "metadata": {},
   "source": [
    "### 5.11. Sampling data for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed892e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ANN = parent_data.sample(N).reset_index(drop=True)\n",
    "X = train_data_ANN.iloc[:,:-1]\n",
    "X.to_csv(r\"Training data 3\\ME_Composite_Design_ANN_round3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16631ded",
   "metadata": {},
   "source": [
    "### 5.12. Importing complete data for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ANN = pd.read_csv(r\"Training data 2\\ME_Composite_Design_ANN_combined.csv\")\n",
    "train_data_ANN = train_data_ANN.sample(frac=1)\n",
    "X = train_data_ANN.iloc[:,1:-1]\n",
    "y = train_data_ANN.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed5b8a",
   "metadata": {},
   "source": [
    "### 5.13. Training a new ANN with training data from all design rounds except last round"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad256b83",
   "metadata": {},
   "source": [
    "#### 5.13.1. Importing combined training dataset from all design rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f109654",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ANN = pd.read_csv(r\"Training data 2\\ME_Composite_Design_ANN_combined.csv\")\n",
    "train_data_ANN = train_data_ANN.sample(frac=1)\n",
    "X = train_data_ANN.iloc[:,1:-1]\n",
    "y = train_data_ANN.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b8e0bb",
   "metadata": {},
   "source": [
    "#### 5.13.2. Training a new ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d245c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_hist = ann.fit(X,y,epochs=200,batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fef121",
   "metadata": {},
   "source": [
    "#### 5.13.2.1. ANN loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d93c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Regression loss')\n",
    "plt.plot(ann_hist.history['root_mean_squared_error'], label='Regression_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8869f",
   "metadata": {},
   "source": [
    "#### 5.13.2.2. Saving the new ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b40510",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.save(\"ann_combined.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354fb4f7",
   "metadata": {},
   "source": [
    "### 5.14.  Prediction of ME coupling coefficients of parent and ANN training data with retrained ANN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcea1c9",
   "metadata": {},
   "source": [
    "#### 5.14.1. Loading the last population data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6513af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data = pd.read_csv(r\"Population_data 2\\pop_data3.csv\")\n",
    "pop_X = pop_data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecfadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec28d3",
   "metadata": {},
   "source": [
    "#### 5.14.2. Predicting coupling coefficient using retrained ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6cdd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pop = pd.DataFrame(ann.predict(pop_X),columns = ['ME_Coupling_coefficient_pred_corrected'])\n",
    "pop_data = pd.concat([pop_data,y_pred_pop],axis=1)\n",
    "pop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ea51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data.to_csv(r\"Population_data 2\\pop_data1_corrected.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb3c858",
   "metadata": {},
   "source": [
    "# 6.Saving models in design rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed77506",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('generator.h5')\n",
    "discriminator.save('discriminator.h5')\n",
    "ann.save('ann.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
